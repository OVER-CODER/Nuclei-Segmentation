{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_TlyB5PHdRAB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import io, color\n",
        "from skimage.transform import resize\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Loading and Processing"
      ],
      "metadata": {
        "id": "kzLzx3rbdW9r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NucleiDataset(Dataset):\n",
        "    def __init__(self, image_dir, mask_dir, image_size=(128, 128)):\n",
        "        self.image_size = image_size\n",
        "        self.image_paths = []\n",
        "        self.mask_paths = []\n",
        "        image_files = sorted(os.listdir(image_dir))\n",
        "        mask_files = sorted(os.listdir(mask_dir))\n",
        "\n",
        "        for img_file, mask_file in zip(image_files, mask_files):\n",
        "            img_path = os.path.join(image_dir, img_file)\n",
        "            mask_path = os.path.join(mask_dir, mask_file)\n",
        "            self.image_paths.append(img_path)\n",
        "            self.mask_paths.append(mask_path)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        mask_path = self.mask_paths[idx]\n",
        "\n",
        "        img = io.imread(img_path)\n",
        "        mask = io.imread(mask_path)\n",
        "\n",
        "        if img.ndim == 3 and img.shape[2] == 4:\n",
        "            img = img[:, :, :3]  # Drop alpha if RGBA\n",
        "\n",
        "        if mask.ndim == 3:\n",
        "            if mask.shape[2] == 4:\n",
        "                mask = mask[:, :, :3]\n",
        "            mask = color.rgb2gray(mask)\n",
        "        elif mask.ndim == 2:\n",
        "            pass  # already grayscale\n",
        "\n",
        "        img_resized = resize(img, self.image_size, anti_aliasing=True)\n",
        "        if img_resized.ndim == 3:\n",
        "            img_gray = color.rgb2gray(img_resized)\n",
        "        else:\n",
        "            img_gray = img_resized\n",
        "\n",
        "        mask_resized = resize(mask, self.image_size, anti_aliasing=True)\n",
        "        mask_binary = mask_resized > 0.5\n",
        "\n",
        "        return torch.tensor(np.expand_dims(img_gray.astype(np.float32), axis=0)), \\\n",
        "               torch.tensor(np.expand_dims(mask_binary.astype(np.float32), axis=0)), \\\n",
        "               resize(img, self.image_size, anti_aliasing=True), \\\n",
        "               resize(mask, self.image_size, anti_aliasing=True) # Return resized original images for visualization"
      ],
      "metadata": {
        "id": "oZjP5USJdak8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Attention U-Net Model"
      ],
      "metadata": {
        "id": "t4QpoJr4dehD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionGate(nn.Module):\n",
        "    def __init__(self, F_g, F_l, F_int):\n",
        "        super(AttentionGate, self).__init__()\n",
        "        self.W_g = nn.Conv2d(F_g, F_int, kernel_size=1, stride=1, padding=0, bias=True)\n",
        "        self.W_x = nn.Conv2d(F_l, F_int, kernel_size=1, stride=1, padding=0, bias=True)\n",
        "        self.psi = nn.Conv2d(F_int, 1, kernel_size=1, stride=1, padding=0, bias=True)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, g, x):\n",
        "        g1 = self.W_g(g)\n",
        "        x1 = self.W_x(x)\n",
        "        psi = self.relu(g1 + x1)\n",
        "        psi = self.sigmoid(self.psi(psi))\n",
        "        return x * psi\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(ConvBlock, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "class UpConv(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(UpConv, self).__init__()\n",
        "        self.up = nn.ConvTranspose2d(in_ch, out_ch, kernel_size=2, stride=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.up(x)\n",
        "\n",
        "class AttentionUNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AttentionUNet, self).__init__()\n",
        "\n",
        "        self.enc1 = ConvBlock(1, 64)\n",
        "        self.pool1 = nn.MaxPool2d(2)\n",
        "\n",
        "        self.enc2 = ConvBlock(64, 128)\n",
        "        self.pool2 = nn.MaxPool2d(2)\n",
        "\n",
        "        self.enc3 = ConvBlock(128, 256)\n",
        "        self.pool3 = nn.MaxPool2d(2)\n",
        "\n",
        "        self.middle = ConvBlock(256, 512)\n",
        "\n",
        "        self.up3 = UpConv(512, 256)\n",
        "        self.attn3 = AttentionGate(F_g=256, F_l=256, F_int=128)\n",
        "        self.dec3 = ConvBlock(256 * 2, 256)\n",
        "\n",
        "        self.up2 = UpConv(256, 128)\n",
        "        self.attn2 = AttentionGate(F_g=128, F_l=128, F_int=64)\n",
        "        self.dec2 = ConvBlock(128 * 2, 128)\n",
        "\n",
        "        self.up1 = UpConv(128, 64)\n",
        "        self.attn1 = AttentionGate(F_g=64, F_l=64, F_int=32)\n",
        "        self.dec1 = ConvBlock(64 * 2, 64)\n",
        "\n",
        "        self.final = nn.Conv2d(64, 1, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        e1 = self.enc1(x)\n",
        "        p1 = self.pool1(e1)\n",
        "\n",
        "        e2 = self.enc2(p1)\n",
        "        p2 = self.pool2(e2)\n",
        "\n",
        "        e3 = self.enc3(p2)\n",
        "        p3 = self.pool3(e3)\n",
        "\n",
        "        m = self.middle(p3)\n",
        "\n",
        "        up3 = self.up3(m)\n",
        "        attn3 = self.attn3(g=up3, x=e3)\n",
        "        d3 = self.dec3(torch.cat([up3, attn3], dim=1))\n",
        "\n",
        "        up2 = self.up2(d3)\n",
        "        attn2 = self.attn2(g=up2, x=e2)\n",
        "        d2 = self.dec2(torch.cat([up2, attn2], dim=1))\n",
        "\n",
        "        up1 = self.up1(d2)\n",
        "        attn1 = self.attn1(g=up1, x=e1)\n",
        "        d1 = self.dec1(torch.cat([up1, attn1], dim=1))\n",
        "\n",
        "        return torch.sigmoid(self.final(d1))"
      ],
      "metadata": {
        "id": "Ne3ltDwidhVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "4nh_uqdidpem"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_unet(model, train_loader, num_epochs=10, lr=1e-3):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model.to(device)\n",
        "    criterion = nn.BCELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        for img_tensor, mask_tensor, _, _ in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
        "            img_tensor, mask_tensor = img_tensor.to(device), mask_tensor.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(img_tensor)\n",
        "            loss = criterion(output, mask_tensor)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss / len(train_loader):.4f}\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "SAkAfwSidstw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prediction"
      ],
      "metadata": {
        "id": "pTiqAgTzdv-z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_unet(model, test_loader):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model.eval()\n",
        "    preds = []\n",
        "    original_images = []\n",
        "    ground_truth_masks = []\n",
        "    with torch.no_grad():\n",
        "        for img_tensor, mask_tensor, original_img, original_mask in tqdm(test_loader, desc=\"Predicting\"):\n",
        "            img_tensor = img_tensor.to(device)\n",
        "            output = model(img_tensor).cpu().numpy()\n",
        "            preds.extend(output)\n",
        "            original_images.extend(original_img)\n",
        "            ground_truth_masks.extend(original_mask)\n",
        "    return np.array(preds), original_images, ground_truth_masks"
      ],
      "metadata": {
        "id": "cCfgCvj6dzNR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation"
      ],
      "metadata": {
        "id": "HNvlMGyBd2NZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(y_true, y_pred, threshold=0.5):\n",
        "    y_pred_binary = y_pred > threshold\n",
        "    y_true_flat = y_true.flatten()\n",
        "    y_pred_flat = y_pred_binary.flatten()\n",
        "\n",
        "    TP = np.sum((y_true_flat == 1) & (y_pred_flat == 1))\n",
        "    TN = np.sum((y_true_flat == 0) & (y_pred_flat == 0))\n",
        "    FP = np.sum((y_true_flat == 0) & (y_pred_flat == 1))\n",
        "    FN = np.sum((y_true_flat == 1) & (y_pred_flat == 0))\n",
        "\n",
        "    precision = TP / (TP + FP + 1e-8)\n",
        "    recall = TP / (TP + FN + 1e-8)\n",
        "    accuracy = (TP + TN) / (TP + TN + FP + FN + 1e-8)\n",
        "    f1_score = 2 * precision * recall / (precision + recall + 1e-8)\n",
        "\n",
        "    return precision, recall, f1_score, accuracy"
      ],
      "metadata": {
        "id": "g5BIlhcdd5mX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualization"
      ],
      "metadata": {
        "id": "OChNR1yqd9HD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_results(original_images, ground_truth_masks, predictions, num_samples=5, save_dir='results/attention_unet'):\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    for i in range(min(num_samples, len(original_images))):\n",
        "        plt.figure(figsize=(15, 5))\n",
        "\n",
        "        # Original image\n",
        "        plt.subplot(1, 3, 1)\n",
        "        if original_images[i].ndim == 3:\n",
        "            plt.imshow(original_images[i])\n",
        "        else:\n",
        "            plt.imshow(original_images[i], cmap='gray')\n",
        "        plt.title('Original Image')\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Ground truth mask\n",
        "        plt.subplot(1, 3, 2)\n",
        "        if ground_truth_masks[i].ndim == 3:\n",
        "            plt.imshow(ground_truth_masks[i])\n",
        "        else:\n",
        "            plt.imshow(ground_truth_masks[i], cmap='gray')\n",
        "        plt.title('Ground Truth Mask')\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Prediction (binarized output)\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.imshow(predictions[i][0] > 0.5, cmap='gray')\n",
        "        plt.title('Prediction')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.savefig(os.path.join(save_dir, f'prediction_result_{i}.png'))\n",
        "        plt.close()"
      ],
      "metadata": {
        "id": "5ZBGRmxAeAhC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Main Execution"
      ],
      "metadata": {
        "id": "zBUCJv-3eD68"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_image_dir = 'NucleiSegmentationDataset/all_images'\n",
        "train_mask_dir = 'NucleiSegmentationDataset/merged_masks'\n",
        "test_image_dir = 'TestDataset/images'\n",
        "test_mask_dir = 'TestDataset/masks'\n",
        "\n",
        "train_dataset = NucleiDataset(train_image_dir, train_mask_dir)\n",
        "test_dataset = NucleiDataset(test_image_dir, test_mask_dir)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "attention_unet_model = AttentionUNet()\n",
        "attention_unet_model = train_unet(attention_unet_model, train_loader, num_epochs=20, lr=0.001)\n",
        "\n",
        "predictions, original_test_images, original_test_masks = predict_unet(attention_unet_model, test_loader)\n",
        "precision, recall, f1, accuracy = compute_metrics(np.array(original_test_masks) > 0.5, predictions > 0.5)\n",
        "print(f'Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}, Accuracy: {accuracy:.4f}')\n",
        "visualize_results(original_test_images, original_test_masks, predictions, num_samples=5)"
      ],
      "metadata": {
        "id": "exu1IX-DeG8B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}