{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-23T17:02:01.410832Z",
          "iopub.status.busy": "2025-05-23T17:02:01.410594Z",
          "iopub.status.idle": "2025-05-23T17:02:05.716675Z",
          "shell.execute_reply": "2025-05-23T17:02:05.715922Z",
          "shell.execute_reply.started": "2025-05-23T17:02:01.410807Z"
        },
        "id": "wCwSYIR3Oa63",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-image in c:\\users\\aryan pandit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.24 in c:\\users\\aryan pandit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-image) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.11.4 in c:\\users\\aryan pandit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-image) (1.13.1)\n",
            "Requirement already satisfied: networkx>=3.0 in c:\\users\\aryan pandit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-image) (3.2.1)\n",
            "Requirement already satisfied: pillow>=10.1 in c:\\users\\aryan pandit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-image) (11.1.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in c:\\users\\aryan pandit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-image) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\aryan pandit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-image) (2025.3.30)\n",
            "Requirement already satisfied: packaging>=21 in c:\\users\\aryan pandit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-image) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in c:\\users\\aryan pandit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-image) (0.4)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install scikit-image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-23T17:47:02.595192Z",
          "iopub.status.busy": "2025-05-23T17:47:02.594482Z",
          "iopub.status.idle": "2025-05-23T17:47:07.296811Z",
          "shell.execute_reply": "2025-05-23T17:47:07.296154Z",
          "shell.execute_reply.started": "2025-05-23T17:47:02.595140Z"
        },
        "id": "td7RbJqHB6Uh",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import io, color\n",
        "from skimage.transform import resize\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import f1_score, jaccard_score, precision_score, recall_score, accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Njue4XF8C4-w"
      },
      "source": [
        "### Data Loading and Processing (Adapt for your dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-23T17:47:10.133287Z",
          "iopub.status.busy": "2025-05-23T17:47:10.132736Z",
          "iopub.status.idle": "2025-05-23T17:47:10.141042Z",
          "shell.execute_reply": "2025-05-23T17:47:10.140325Z",
          "shell.execute_reply.started": "2025-05-23T17:47:10.133264Z"
        },
        "id": "6SGvxjx5C8VK",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class NucleiDataset(Dataset):\n",
        "    def __init__(self, image_dir, mask_dir, image_size=(128, 128)):\n",
        "        self.image_size = image_size\n",
        "        self.image_paths = []\n",
        "        self.mask_paths = []\n",
        "        self.image_filenames = []\n",
        "        image_files = sorted(os.listdir(image_dir))\n",
        "        mask_files = sorted(os.listdir(mask_dir))\n",
        "\n",
        "        for img_file, mask_file in zip(image_files, mask_files):\n",
        "            img_path = os.path.join(image_dir, img_file)\n",
        "            mask_path = os.path.join(mask_dir, mask_file)\n",
        "            self.image_paths.append(img_path)\n",
        "            self.mask_paths.append(mask_path)\n",
        "            self.image_filenames.append(img_file)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        mask_path = self.mask_paths[idx]\n",
        "        img_filename = self.image_filenames[idx]\n",
        "\n",
        "        img = io.imread(img_path)\n",
        "        mask = io.imread(mask_path)\n",
        "\n",
        "        if img.ndim == 3 and img.shape[2] == 4:\n",
        "            img = img[:, :, :3]  # Drop alpha if RGBA\n",
        "\n",
        "        if mask.ndim == 3:\n",
        "            if mask.shape[2] == 4:\n",
        "                mask = mask[:, :, :3]\n",
        "            mask = color.rgb2gray(mask)\n",
        "        elif mask.ndim == 2:\n",
        "            pass  # already grayscale\n",
        "\n",
        "        img_resized = resize(img, self.image_size, anti_aliasing=True)\n",
        "        if img_resized.ndim == 3:\n",
        "            img_gray = color.rgb2gray(img_resized)\n",
        "        else:\n",
        "            img_gray = img_resized\n",
        "\n",
        "        mask_resized = resize(mask, self.image_size, anti_aliasing=True)\n",
        "        mask_binary = mask_resized > 0.5\n",
        "\n",
        "        return torch.tensor(np.expand_dims(img_gray.astype(np.float32), axis=0)).to(device), \\\n",
        "               torch.tensor(np.expand_dims(mask_binary.astype(np.float32), axis=0)).to(device), \\\n",
        "               resize(img, self.image_size, anti_aliasing=True), \\\n",
        "               resize(mask, self.image_size, anti_aliasing=True), \\\n",
        "               img_filename"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tD0-yw4TCk3-"
      },
      "source": [
        "### Hybrid Attention Module (HAM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-23T17:47:09.381784Z",
          "iopub.status.busy": "2025-05-23T17:47:09.381377Z",
          "iopub.status.idle": "2025-05-23T17:47:09.392781Z",
          "shell.execute_reply": "2025-05-23T17:47:09.392195Z",
          "shell.execute_reply.started": "2025-05-23T17:47:09.381761Z"
        },
        "id": "YJea7sOmCoSk",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class HybridAttention(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(HybridAttention, self).__init__()\n",
        "        self.channel_attention = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Conv2d(in_channels, in_channels // 8, kernel_size=1).to(device),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels // 8, in_channels, kernel_size=1).to(device),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        self.spatial_attention = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, in_channels // 8, kernel_size=1).to(device),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels // 8, 1, kernel_size=3, padding=1).to(device),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        channel_attn = self.channel_attention(x)\n",
        "        spatial_attn = self.spatial_attention(x)\n",
        "        channel_refined = x * channel_attn\n",
        "        spatial_refined = x * spatial_attn\n",
        "        # Novel combination: Element-wise multiplication of channel and spatial refined features\n",
        "        attention_out = channel_refined * spatial_refined\n",
        "        return x + attention_out\n",
        "\n",
        "class InceptionModule(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels_1x1, red_channels_3x3, out_channels_3x3, red_channels_5x5, out_channels_5x5, pool_proj):\n",
        "        super(InceptionModule, self).__init__()\n",
        "        self.branch1 = nn.Conv2d(in_channels, out_channels_1x1, kernel_size=1).to(device)\n",
        "        self.branch2_red = nn.Conv2d(in_channels, red_channels_3x3, kernel_size=1).to(device)\n",
        "        self.branch2_conv = nn.Conv2d(red_channels_3x3, out_channels_3x3, kernel_size=3, padding=1).to(device)\n",
        "        self.branch3_red = nn.Conv2d(in_channels, red_channels_5x5, kernel_size=1).to(device)\n",
        "        self.branch3_conv = nn.Conv2d(red_channels_5x5, out_channels_5x5, kernel_size=5, padding=2).to(device)\n",
        "        self.branch4_pool = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
        "        self.branch4_proj = nn.Conv2d(in_channels, pool_proj, kernel_size=1).to(device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        branch1_out = F.relu(self.branch1(x))\n",
        "        branch2_out = F.relu(self.branch2_conv(F.relu(self.branch2_red(x))))\n",
        "        branch3_out = F.relu(self.branch3_conv(F.relu(self.branch3_red(x))))\n",
        "        branch4_out = F.relu(F.relu(self.branch4_proj(self.branch4_pool(x))))\n",
        "        outputs = [branch1_out, branch2_out, branch3_out, branch4_out]\n",
        "        return torch.cat(outputs, 1)\n",
        "\n",
        "class HMSAModule(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels_1x1, red_channels_3x3, out_channels_3x3, red_channels_5x5, out_channels_5x5, pool_proj):\n",
        "        super(HMSAModule, self).__init__()\n",
        "        self.inception = InceptionModule(in_channels, out_channels_1x1, red_channels_3x3, out_channels_3x3, red_channels_5x5, out_channels_5x5, pool_proj).to(device)\n",
        "        inception_output_channels = out_channels_1x1 + out_channels_3x3 + out_channels_5x5 + pool_proj\n",
        "        self.attention = HybridAttention(inception_output_channels).to(device)\n",
        "        if inception_output_channels != in_channels:\n",
        "            self.projection = nn.Conv2d(inception_output_channels, in_channels, kernel_size=1).to(device)\n",
        "        else:\n",
        "            self.projection = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        inception_out = self.inception(x)\n",
        "        attention_out = self.attention(inception_out)\n",
        "        if self.projection is not None:\n",
        "            attention_out = self.projection(attention_out)\n",
        "        hmsam_output = x + attention_out\n",
        "        return hmsam_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40DGtAzoCvE2"
      },
      "source": [
        "### HMSAM-UNet Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-23T17:47:09.788599Z",
          "iopub.status.busy": "2025-05-23T17:47:09.788324Z",
          "iopub.status.idle": "2025-05-23T17:47:09.798132Z",
          "shell.execute_reply": "2025-05-23T17:47:09.797455Z",
          "shell.execute_reply.started": "2025-05-23T17:47:09.788579Z"
        },
        "id": "hgUzlAcHCyOb",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "class HMSAM_UNet(nn.Module):\n",
        "    def __init__(self, in_channels=1, out_channels=1):\n",
        "        super(HMSAM_UNet, self).__init__()\n",
        "        def double_conv(in_c, out_c):\n",
        "            return nn.Sequential(\n",
        "                nn.Conv2d(in_c, out_c, kernel_size=3, padding=1).to(device),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Conv2d(out_c, out_c, kernel_size=3, padding=1).to(device),\n",
        "                nn.ReLU(inplace=True)\n",
        "            )\n",
        "\n",
        "        self.enc1 = double_conv(in_channels, 64)\n",
        "        self.pool1 = nn.MaxPool2d(2)\n",
        "        self.enc2 = double_conv(64, 128)\n",
        "        self.pool2 = nn.MaxPool2d(2)\n",
        "        self.enc3 = double_conv(128, 256)\n",
        "        self.pool3 = nn.MaxPool2d(2)\n",
        "        self.enc4 = double_conv(256, 512)\n",
        "        self.pool4 = nn.MaxPool2d(2)\n",
        "\n",
        "        self.hmsam = HMSAModule(in_channels=512,\n",
        "                                out_channels_1x1=128,\n",
        "                                red_channels_3x3=96, out_channels_3x3=192,\n",
        "                                red_channels_5x5=32, out_channels_5x5=64,\n",
        "                                pool_proj=128)\n",
        "\n",
        "        self.upconv4 = nn.ConvTranspose2d(512, 512, kernel_size=2, stride=2).to(device)\n",
        "        self.dec4 = double_conv(1024, 512)\n",
        "\n",
        "        self.upconv3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2).to(device)\n",
        "        self.dec3 = double_conv(512, 256)\n",
        "\n",
        "        self.upconv2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2).to(device)\n",
        "        self.dec2 = double_conv(256, 128)\n",
        "\n",
        "        self.upconv1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2).to(device)\n",
        "        self.dec1 = double_conv(128, 64)\n",
        "\n",
        "        self.outc = nn.Conv2d(64, out_channels, kernel_size=1).to(device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        enc1 = self.enc1(x)\n",
        "        enc2 = self.enc2(self.pool1(enc1))\n",
        "        enc3 = self.enc3(self.pool2(enc2))\n",
        "        enc4 = self.enc4(self.pool3(enc3))\n",
        "        bridge = self.pool4(enc4)\n",
        "\n",
        "        hmsam_out = self.hmsam(bridge)\n",
        "\n",
        "        dec4 = self.dec4(torch.cat([self.upconv4(hmsam_out), enc4], dim=1))\n",
        "        dec3 = self.dec3(torch.cat([self.upconv3(dec4), enc3], dim=1))\n",
        "        dec2 = self.dec2(torch.cat([self.upconv2(dec3), enc2], dim=1))\n",
        "        dec1 = self.dec1(torch.cat([self.upconv1(dec2), enc1], dim=1))\n",
        "\n",
        "        out = torch.sigmoid(self.outc(dec1))\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykBzC_QODCaO"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-23T17:47:10.721306Z",
          "iopub.status.busy": "2025-05-23T17:47:10.720807Z",
          "iopub.status.idle": "2025-05-23T17:47:10.726565Z",
          "shell.execute_reply": "2025-05-23T17:47:10.725905Z",
          "shell.execute_reply.started": "2025-05-23T17:47:10.721279Z"
        },
        "id": "rfRNiyCMDEQC",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def train_unet(model, train_loader, num_epochs=10, lr=1e-3):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model.to(device)\n",
        "    criterion = nn.BCELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        for img_tensor, mask_tensor, _, _, _ in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
        "            img_tensor, mask_tensor = img_tensor.to(device), mask_tensor.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(img_tensor)\n",
        "            loss = criterion(output, mask_tensor)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss / len(train_loader):.4f}\")\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zS3FKOE8DHqf"
      },
      "source": [
        "### Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-23T17:47:11.239791Z",
          "iopub.status.busy": "2025-05-23T17:47:11.239114Z",
          "iopub.status.idle": "2025-05-23T17:47:11.244621Z",
          "shell.execute_reply": "2025-05-23T17:47:11.243771Z",
          "shell.execute_reply.started": "2025-05-23T17:47:11.239765Z"
        },
        "id": "7qyIvVRDDLnn",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def predict_unet(model, test_loader):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    original_images = []\n",
        "    ground_truth_masks = []\n",
        "    image_filenames = []\n",
        "    with torch.no_grad():\n",
        "        for img_tensor, mask_tensor, original_img, original_mask, filename in tqdm(test_loader, desc=\"Predicting\"):\n",
        "            img_tensor = img_tensor.to(device)\n",
        "            output = model(img_tensor).cpu().numpy()\n",
        "            predictions.append((output[0], filename[0]))\n",
        "            original_images.extend(original_img)\n",
        "            ground_truth_masks.extend(original_mask)\n",
        "            image_filenames.extend(filename)\n",
        "    return predictions, original_images, ground_truth_masks, image_filenames"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zm1tngWWDO2I"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-23T17:47:11.982005Z",
          "iopub.status.busy": "2025-05-23T17:47:11.981756Z",
          "iopub.status.idle": "2025-05-23T17:47:11.987104Z",
          "shell.execute_reply": "2025-05-23T17:47:11.986461Z",
          "shell.execute_reply.started": "2025-05-23T17:47:11.981987Z"
        },
        "id": "SyMlz92PDR1x",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def evaluate_predictions(predictions, gt_masks):\n",
        "    dice_scores = []\n",
        "    iou_scores = []\n",
        "    precisions = []\n",
        "    recalls = []\n",
        "    accuracies = []\n",
        "\n",
        "    for pred_mask, fname in predictions:\n",
        "        gt_mask = gt_masks.get(fname)\n",
        "        if gt_mask is None:\n",
        "            print(f\"Ground truth for {fname} not found.\")\n",
        "            continue\n",
        "\n",
        "        pred_mask_binary = (pred_mask > 0.5).flatten().astype(np.uint8)\n",
        "        gt_mask_array = gt_mask.cpu().numpy()\n",
        "        gt_mask_binary = (gt_mask_array > 0.5).flatten().astype(np.uint8)\n",
        "\n",
        "        dice = f1_score(gt_mask_binary, pred_mask_binary)\n",
        "        iou = jaccard_score(gt_mask_binary, pred_mask_binary)\n",
        "        precision = precision_score(gt_mask_binary, pred_mask_binary, zero_division=0)\n",
        "        recall = recall_score(gt_mask_binary, pred_mask_binary, zero_division=0)\n",
        "        accuracy = accuracy_score(gt_mask_binary, pred_mask_binary)\n",
        "\n",
        "        dice_scores.append(dice)\n",
        "        iou_scores.append(iou)\n",
        "        precisions.append(precision)\n",
        "        recalls.append(recall)\n",
        "        accuracies.append(accuracy)\n",
        "\n",
        "    print(\"\\nEvaluation Metrics:\")\n",
        "    print(f\"Dice Score (F1):  {np.mean(dice_scores):.4f}\")\n",
        "    print(f\"IoU Score:        {np.mean(iou_scores):.4f}\")\n",
        "    print(f\"Precision:        {np.mean(precisions):.4f}\")\n",
        "    print(f\"Recall:           {np.mean(recalls):.4f}\")\n",
        "    print(f\"Accuracy:         {np.mean(accuracies):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Apwy7BoJDUlh"
      },
      "source": [
        "### Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-23T17:47:12.769212Z",
          "iopub.status.busy": "2025-05-23T17:47:12.768641Z",
          "iopub.status.idle": "2025-05-23T17:47:12.775307Z",
          "shell.execute_reply": "2025-05-23T17:47:12.774459Z",
          "shell.execute_reply.started": "2025-05-23T17:47:12.769179Z"
        },
        "id": "Zd9YOX6zDXse",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def visualize_results(original_images, ground_truth_masks, predictions, num_samples=5, save_dir='results/hmsam_unet'):\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    for i in range(min(num_samples, len(original_images))):\n",
        "        plt.figure(figsize=(15, 5))\n",
        "\n",
        "        # Original image\n",
        "        plt.subplot(1, 3, 1)\n",
        "        img_to_plot = original_images[i].squeeze(0)\n",
        "        if img_to_plot.ndim == 3:\n",
        "            plt.imshow(img_to_plot)\n",
        "        else:\n",
        "            plt.imshow(img_to_plot, cmap='gray')\n",
        "        plt.title('Original Image')\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Ground truth mask\n",
        "        plt.subplot(1, 3, 2)\n",
        "        mask_to_plot = ground_truth_masks[i].squeeze(0)\n",
        "        if mask_to_plot.ndim == 3:\n",
        "            plt.imshow(mask_to_plot)\n",
        "        else:\n",
        "            plt.imshow(mask_to_plot, cmap='gray')\n",
        "        plt.title('Ground Truth Mask')\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Prediction (binarized output)\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.imshow(predictions[i][0] > 0.5, cmap='gray')\n",
        "        plt.title('Prediction')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.savefig(os.path.join(save_dir, f'prediction_result_{i}.png'))\n",
        "        plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKtv8InsDbhh"
      },
      "source": [
        "### Main Execution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-05-23T17:55:06.897588Z",
          "iopub.status.busy": "2025-05-23T17:55:06.897316Z",
          "iopub.status.idle": "2025-05-23T18:23:55.898952Z",
          "shell.execute_reply": "2025-05-23T18:23:55.898238Z",
          "shell.execute_reply.started": "2025-05-23T17:55:06.897567Z"
        },
        "id": "LMFV9LyXDfiD",
        "outputId": "23a06e01-ecf9-41f9-8592-63536012a03d",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/25: 100%|██████████| 167/167 [03:43<00:00,  1.34s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25, Loss: 0.2846\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/25: 100%|██████████| 167/167 [03:42<00:00,  1.33s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/25, Loss: 0.6377\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/25: 100%|██████████| 167/167 [03:46<00:00,  1.36s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/25, Loss: 0.1577\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/25: 100%|██████████| 167/167 [03:28<00:00,  1.25s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/25, Loss: 0.1155\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/25:  81%|████████▏ | 136/167 [03:07<00:48,  1.56s/it]"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "    train_image_dir = 'NucleiSegmentationDataset/all_images'\n",
        "    train_mask_dir = 'NucleiSegmentationDataset/merged_masks'\n",
        "    test_image_dir = 'TestDataset/images'\n",
        "    test_mask_dir = 'TestDataset/masks'\n",
        "    # train_image_dir = '/content/drive/MyDrive/NucleiSegmentation/TestDataset/images'\n",
        "    # train_mask_dir = '/content/drive/MyDrive/NucleiSegmentation/TestDataset/masks'\n",
        "\n",
        "    train_dataset = NucleiDataset(train_image_dir, train_mask_dir)\n",
        "    test_dataset = NucleiDataset(test_image_dir, test_mask_dir)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(device)\n",
        "    hmsam_unet_model = HMSAM_UNet(in_channels=1, out_channels=1)\n",
        "\n",
        "    hmsam_unet_model = train_unet(hmsam_unet_model, train_loader, num_epochs=25, lr=0.001) # Reduced epochs for quicker test\n",
        "\n",
        "    predictions, original_test_images, original_test_masks, test_filenames = predict_unet(hmsam_unet_model, test_loader)\n",
        "\n",
        "\n",
        "    gt_masks_for_eval = {}\n",
        "    for mask, filename in zip(original_test_masks, test_filenames):\n",
        "        gt_masks_for_eval[filename] = mask\n",
        "\n",
        "    evaluate_predictions(predictions, gt_masks_for_eval)\n",
        "    visualize_results(original_test_images, original_test_masks, predictions, num_samples=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GtehenfYOa7J",
        "trusted": true
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 1454704,
          "sourceId": 2407101,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 7492953,
          "sourceId": 11918784,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 31040,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
