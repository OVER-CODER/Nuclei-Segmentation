{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kKF2-WOVYrii"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import io, color\n",
        "from skimage.transform import resize\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzoyKOU7YwrC"
      },
      "source": [
        "### Data Loading and Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPtQsMTzY3sA"
      },
      "outputs": [],
      "source": [
        "class NucleiDataset(Dataset):\n",
        "    def __init__(self, image_dir, mask_dir, image_size=(128, 128)):\n",
        "        self.image_size = image_size\n",
        "        self.image_paths = []\n",
        "        self.mask_paths = []\n",
        "        image_files = sorted(os.listdir(image_dir))\n",
        "        mask_files = sorted(os.listdir(mask_dir))\n",
        "\n",
        "        for img_file, mask_file in zip(image_files, mask_files):\n",
        "            img_path = os.path.join(image_dir, img_file)\n",
        "            mask_path = os.path.join(mask_dir, mask_file)\n",
        "            self.image_paths.append(img_path)\n",
        "            self.mask_paths.append(mask_path)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        mask_path = self.mask_paths[idx]\n",
        "\n",
        "        img = io.imread(img_path)\n",
        "        mask = io.imread(mask_path)\n",
        "\n",
        "        if img.ndim == 3 and img.shape[2] == 4:\n",
        "            img = img[:, :, :3]  # Drop alpha if RGBA\n",
        "\n",
        "        if mask.ndim == 3:\n",
        "            if mask.shape[2] == 4:\n",
        "                mask = mask[:, :, :3]\n",
        "            mask = color.rgb2gray(mask)\n",
        "        elif mask.ndim == 2:\n",
        "            pass  # already grayscale\n",
        "\n",
        "        img_resized = resize(img, self.image_size, anti_aliasing=True)\n",
        "        if img_resized.ndim == 3:\n",
        "            img_gray = color.rgb2gray(img_resized)\n",
        "        else:\n",
        "            img_gray = img_resized\n",
        "\n",
        "        mask_resized = resize(mask, self.image_size, anti_aliasing=True)\n",
        "        mask_binary = mask_resized > 0.5\n",
        "\n",
        "        return torch.tensor(np.expand_dims(img_gray.astype(np.float32), axis=0)), \\\n",
        "               torch.tensor(np.expand_dims(mask_binary.astype(np.float32), axis=0)), \\\n",
        "               resize(img, self.image_size, anti_aliasing=True), \\\n",
        "               resize(mask, self.image_size, anti_aliasing=True) # Return resized original images for visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-tC-C7nY4l2"
      },
      "source": [
        "### Residual U-Net (ResUNet) Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8rSSewpPY80s"
      },
      "outputs": [],
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, stride=1):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_ch, out_ch, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_ch)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_ch, out_ch, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_ch)\n",
        "        self.downsample = None\n",
        "        if stride != 1 or in_ch != out_ch:\n",
        "            self.downsample = nn.Sequential(\n",
        "                nn.Conv2d(in_ch, out_ch, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_ch)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        if self.downsample:\n",
        "            residual = self.downsample(x)\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "class UpSample(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(UpSample, self).__init__()\n",
        "        self.up = nn.ConvTranspose2d(in_ch, out_ch, kernel_size=2, stride=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.up(x)\n",
        "\n",
        "class ResUNet(nn.Module):\n",
        "    def __init__(self, num_channels=1):\n",
        "        super(ResUNet, self).__init__()\n",
        "\n",
        "        self.enc1_res1 = ResidualBlock(num_channels, 64)\n",
        "        self.enc1_res2 = ResidualBlock(64, 64)\n",
        "        self.pool1 = nn.MaxPool2d(2)\n",
        "\n",
        "        self.enc2_res1 = ResidualBlock(64, 128)\n",
        "        self.enc2_res2 = ResidualBlock(128, 128)\n",
        "        self.pool2 = nn.MaxPool2d(2)\n",
        "\n",
        "        self.enc3_res1 = ResidualBlock(128, 256)\n",
        "        self.enc3_res2 = ResidualBlock(256, 256)\n",
        "        self.pool3 = nn.MaxPool2d(2)\n",
        "\n",
        "        self.middle_res1 = ResidualBlock(256, 512)\n",
        "        self.middle_res2 = ResidualBlock(512, 512)\n",
        "\n",
        "        self.up3 = UpSample(512, 256)\n",
        "        self.dec3_res1 = ResidualBlock(256 + 256, 256)\n",
        "        self.dec3_res2 = ResidualBlock(256, 256)\n",
        "\n",
        "        self.up2 = UpSample(256, 128)\n",
        "        self.dec2_res1 = ResidualBlock(128 + 128, 128)\n",
        "        self.dec2_res2 = ResidualBlock(128, 128)\n",
        "\n",
        "        self.up1 = UpSample(128, 64)\n",
        "        self.dec1_res1 = ResidualBlock(64 + 64, 64)\n",
        "        self.dec1_res2 = ResidualBlock(64, 64)\n",
        "\n",
        "        self.final = nn.Conv2d(64, 1, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encoder\n",
        "        e1 = self.enc1_res2(self.enc1_res1(x))\n",
        "        p1 = self.pool1(e1)\n",
        "\n",
        "        e2 = self.enc2_res2(self.enc2_res1(p1))\n",
        "        p2 = self.pool2(e2)\n",
        "\n",
        "        e3 = self.enc3_res2(self.enc3_res1(p2))\n",
        "        p3 = self.pool3(e3)\n",
        "\n",
        "        # Middle\n",
        "        m = self.middle_res2(self.middle_res1(p3))\n",
        "\n",
        "        # Decoder\n",
        "        up3 = self.up3(m)\n",
        "        d3 = self.dec3_res2(self.dec3_res1(torch.cat([up3, e3], dim=1)))\n",
        "\n",
        "        up2 = self.up2(d3)\n",
        "        d2 = self.dec2_res2(self.dec2_res1(torch.cat([up2, e2], dim=1)))\n",
        "\n",
        "        up1 = self.up1(d2)\n",
        "        d1 = self.dec1_res2(self.dec1_res1(torch.cat([up1, e1], dim=1)))\n",
        "\n",
        "        return torch.sigmoid(self.final(d1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBc_5ZU7ZD-d"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J51nFsXTZHoM"
      },
      "outputs": [],
      "source": [
        "def train_unet(model, train_loader, num_epochs=10, lr=1e-3):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model.to(device)\n",
        "    criterion = nn.BCELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        for img_tensor, mask_tensor, _, _ in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
        "            img_tensor, mask_tensor = img_tensor.to(device), mask_tensor.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(img_tensor)\n",
        "            loss = criterion(output, mask_tensor)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss / len(train_loader):.4f}\")\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJiHFIMcZKjp"
      },
      "source": [
        "### Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T5vB9QcmZN7k"
      },
      "outputs": [],
      "source": [
        "def predict_unet(model, test_loader):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model.eval()\n",
        "    preds = []\n",
        "    original_images = []\n",
        "    ground_truth_masks = []\n",
        "    with torch.no_grad():\n",
        "        for img_tensor, mask_tensor, original_img, original_mask in tqdm(test_loader, desc=\"Predicting\"):\n",
        "            img_tensor = img_tensor.to(device)\n",
        "            output = model(img_tensor).cpu().numpy()\n",
        "            preds.extend(output)\n",
        "            original_images.extend(original_img)\n",
        "            ground_truth_masks.extend(original_mask)\n",
        "    return np.array(preds), original_images, ground_truth_masks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxT6wQGwZQab"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YGKQz8uiZTUe"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(y_true, y_pred, threshold=0.5):\n",
        "    y_pred_binary = y_pred > threshold\n",
        "    y_true_flat = y_true.flatten()\n",
        "    y_pred_flat = y_pred_binary.flatten()\n",
        "\n",
        "    TP = np.sum((y_true_flat == 1) & (y_pred_flat == 1))\n",
        "    TN = np.sum((y_true_flat == 0) & (y_pred_flat == 0))\n",
        "    FP = np.sum((y_true_flat == 0) & (y_pred_flat == 1))\n",
        "    FN = np.sum((y_true_flat == 1) & (y_pred_flat == 0))\n",
        "\n",
        "    precision = TP / (TP + FP + 1e-8)\n",
        "    recall = TP / (TP + FN + 1e-8)\n",
        "    accuracy = (TP + TN) / (TP + TN + FP + FN + 1e-8)\n",
        "    f1_score = 2 * precision * recall / (precision + recall + 1e-8)\n",
        "\n",
        "    return precision, recall, f1_score, accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JojaXHZ2ZX01"
      },
      "source": [
        "### Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67sIs0wrZgkQ"
      },
      "outputs": [],
      "source": [
        "def visualize_results(original_images, ground_truth_masks, predictions, num_samples=5, save_dir='results/resunet'):\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    for i in range(min(num_samples, len(original_images))):\n",
        "        plt.figure(figsize=(15, 5))\n",
        "\n",
        "        # Original image\n",
        "        plt.subplot(1, 3, 1)\n",
        "        if original_images[i].ndim == 3:\n",
        "            plt.imshow(original_images[i])\n",
        "        else:\n",
        "            plt.imshow(original_images[i], cmap='gray')\n",
        "        plt.title('Original Image')\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Ground truth mask\n",
        "        plt.subplot(1, 3, 2)\n",
        "        if ground_truth_masks[i].ndim == 3:\n",
        "            plt.imshow(ground_truth_masks[i])\n",
        "        else:\n",
        "            plt.imshow(ground_truth_masks[i], cmap='gray')\n",
        "        plt.title('Ground Truth Mask')\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Prediction (binarized output)\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.imshow(predictions[i][0] > 0.5, cmap='gray')\n",
        "        plt.title('Prediction')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.savefig(os.path.join(save_dir, f'prediction_result_{i}.png'))\n",
        "        plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcbnGiWJZjYw"
      },
      "source": [
        "### Main Execution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "COCxZIqmZk6q"
      },
      "outputs": [],
      "source": [
        "train_image_dir = 'NucleiSegmentationDataset/all_images'\n",
        "train_mask_dir = 'NucleiSegmentationDataset/merged_masks'\n",
        "test_image_dir = 'TestDataset/images'\n",
        "test_mask_dir = 'TestDataset/masks'\n",
        "\n",
        "train_dataset = NucleiDataset(train_image_dir, train_mask_dir)\n",
        "test_dataset = NucleiDataset(test_image_dir, test_mask_dir)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "model = ResUNet(num_channels=1)\n",
        "model = train_unet(model, train_loader, num_epochs=10, lr=1e-3)\n",
        "\n",
        "preds, original_images, ground_truth_masks = predict_unet(model, test_loader)\n",
        "precision, recall, f1_score, accuracy = compute_metrics(np.array(ground_truth_masks) > 0.5, preds > 0.5)\n",
        "print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1_score:.4f}, Accuracy: {accuracy:.4f}\")\n",
        "visualize_results(original_images, ground_truth_masks, preds, num_samples=5)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
