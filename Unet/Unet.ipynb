{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4sTS_C8XbLgN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import io, color\n",
        "from skimage.transform import resize\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Loading and Processing"
      ],
      "metadata": {
        "id": "oCe7vjT-b7Ws"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NucleiDataset(Dataset):\n",
        "    def __init__(self, image_dir, mask_dir, image_size=(128, 128)):\n",
        "        self.image_size = image_size\n",
        "        self.image_paths = []\n",
        "        self.mask_paths = []\n",
        "        image_files = sorted(os.listdir(image_dir))\n",
        "        mask_files = sorted(os.listdir(mask_dir))\n",
        "\n",
        "        for img_file, mask_file in zip(image_files, mask_files):\n",
        "            img_path = os.path.join(image_dir, img_file)\n",
        "            mask_path = os.path.join(mask_dir, mask_file)\n",
        "            self.image_paths.append(img_path)\n",
        "            self.mask_paths.append(mask_path)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        mask_path = self.mask_paths[idx]\n",
        "\n",
        "        img = io.imread(img_path)\n",
        "        mask = io.imread(mask_path)\n",
        "\n",
        "        if img.ndim == 3 and img.shape[2] == 4:\n",
        "            img = img[:, :, :3]  # Drop alpha if RGBA\n",
        "\n",
        "        if mask.ndim == 3:\n",
        "            if mask.shape[2] == 4:\n",
        "                mask = mask[:, :, :3]\n",
        "            mask = color.rgb2gray(mask)\n",
        "        elif mask.ndim == 2:\n",
        "            pass  # already grayscale\n",
        "\n",
        "        img_resized = resize(img, self.image_size, anti_aliasing=True)\n",
        "        if img_resized.ndim == 3:\n",
        "            img_gray = color.rgb2gray(img_resized)\n",
        "        else:\n",
        "            img_gray = img_resized\n",
        "\n",
        "        mask_resized = resize(mask, self.image_size, anti_aliasing=True)\n",
        "        mask_binary = mask_resized > 0.5\n",
        "\n",
        "        return torch.tensor(np.expand_dims(img_gray.astype(np.float32), axis=0)), \\\n",
        "               torch.tensor(np.expand_dims(mask_binary.astype(np.float32), axis=0)), \\\n",
        "               resize(img, self.image_size, anti_aliasing=True), \\\n",
        "               resize(mask, self.image_size, anti_aliasing=True) # Return resized original images for visualization"
      ],
      "metadata": {
        "id": "Po7zlA-Eb90L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### U-Net Model"
      ],
      "metadata": {
        "id": "46h42xcvcCQA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class UNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(UNet, self).__init__()\n",
        "        def conv_block(in_ch, out_ch):\n",
        "            return nn.Sequential(\n",
        "                nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1),\n",
        "                nn.ReLU(inplace=True)\n",
        "            )\n",
        "\n",
        "        self.enc1 = conv_block(1, 64)\n",
        "        self.pool1 = nn.MaxPool2d(2)\n",
        "        self.enc2 = conv_block(64, 128)\n",
        "        self.pool2 = nn.MaxPool2d(2)\n",
        "        self.enc3 = conv_block(128, 256)\n",
        "        self.pool3 = nn.MaxPool2d(2)\n",
        "\n",
        "        self.middle = conv_block(256, 512)\n",
        "\n",
        "        self.up3 = nn.ConvTranspose2d(512, 256, 2, stride=2)\n",
        "        self.dec3 = conv_block(512, 256)\n",
        "        self.up2 = nn.ConvTranspose2d(256, 128, 2, stride=2)\n",
        "        self.dec2 = conv_block(256, 128)\n",
        "        self.up1 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
        "        self.dec1 = conv_block(128, 64)\n",
        "\n",
        "        self.final = nn.Conv2d(64, 1, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        e1 = self.enc1(x)\n",
        "        e2 = self.enc2(self.pool1(e1))\n",
        "        e3 = self.enc3(self.pool2(e2))\n",
        "\n",
        "        m = self.middle(self.pool3(e3))\n",
        "\n",
        "        d3 = self.dec3(torch.cat([self.up3(m), e3], dim=1))\n",
        "        d2 = self.dec2(torch.cat([self.up2(d3), e2], dim=1))\n",
        "        d1 = self.dec1(torch.cat([self.up1(d2), e1], dim=1))\n",
        "\n",
        "        return torch.sigmoid(self.final(d1))"
      ],
      "metadata": {
        "id": "hgc-6SXtcFbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "F6imIHdYcKBa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_unet(model, train_loader, num_epochs=10, lr=1e-3):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model.to(device)\n",
        "    criterion = nn.BCELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        for img_tensor, mask_tensor, _, _ in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
        "            img_tensor, mask_tensor = img_tensor.to(device), mask_tensor.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(img_tensor)\n",
        "            loss = criterion(output, mask_tensor)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss / len(train_loader):.4f}\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "VNa8pCBQcP12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prediction"
      ],
      "metadata": {
        "id": "Jjojv02icSXL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_unet(model, test_loader):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model.eval()\n",
        "    preds = []\n",
        "    original_images = []\n",
        "    ground_truth_masks = []\n",
        "    with torch.no_grad():\n",
        "        for img_tensor, mask_tensor, original_img, original_mask in tqdm(test_loader, desc=\"Predicting\"):\n",
        "            img_tensor = img_tensor.to(device)\n",
        "            output = model(img_tensor).cpu().numpy()\n",
        "            preds.extend(output)\n",
        "            original_images.extend(original_img)\n",
        "            ground_truth_masks.extend(original_mask)\n",
        "    return np.array(preds), original_images, ground_truth_masks"
      ],
      "metadata": {
        "id": "X8qrLAMYcWNy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation"
      ],
      "metadata": {
        "id": "S4D3WLlkcabN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(y_true, y_pred, threshold=0.5):\n",
        "    y_pred_binary = y_pred > threshold\n",
        "    y_true_flat = y_true.flatten()\n",
        "    y_pred_flat = y_pred_binary.flatten()\n",
        "\n",
        "    TP = np.sum((y_true_flat == 1) & (y_pred_flat == 1))\n",
        "    TN = np.sum((y_true_flat == 0) & (y_pred_flat == 0))\n",
        "    FP = np.sum((y_true_flat == 0) & (y_pred_flat == 1))\n",
        "    FN = np.sum((y_true_flat == 1) & (y_pred_flat == 0))\n",
        "\n",
        "    precision = TP / (TP + FP + 1e-8)\n",
        "    recall = TP / (TP + FN + 1e-8)\n",
        "    accuracy = (TP + TN) / (TP + TN + FP + FN + 1e-8)\n",
        "    f1_score = 2 * precision * recall / (precision + recall + 1e-8)\n",
        "\n",
        "    return precision, recall, f1_score, accuracy"
      ],
      "metadata": {
        "id": "jiPQR5l2cyKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualization"
      ],
      "metadata": {
        "id": "loC_C4JCcy3l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_results(original_images, ground_truth_masks, predictions, num_samples=5, save_dir='results/unet'):\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    for i in range(min(num_samples, len(original_images))):\n",
        "        plt.figure(figsize=(15, 5))\n",
        "\n",
        "        # Original image\n",
        "        plt.subplot(1, 3, 1)\n",
        "        if original_images[i].ndim == 3:\n",
        "            plt.imshow(original_images[i])\n",
        "        else:\n",
        "            plt.imshow(original_images[i], cmap='gray')\n",
        "        plt.title('Original Image')\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Ground truth mask\n",
        "        plt.subplot(1, 3, 2)\n",
        "        if ground_truth_masks[i].ndim == 3:\n",
        "            plt.imshow(ground_truth_masks[i])\n",
        "        else:\n",
        "            plt.imshow(ground_truth_masks[i], cmap='gray')\n",
        "        plt.title('Ground Truth Mask')\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Prediction (binarized output)\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.imshow(predictions[i][0] > 0.5, cmap='gray')\n",
        "        plt.title('Prediction')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.savefig(os.path.join(save_dir, f'prediction_result_{i}.png'))\n",
        "        plt.close()"
      ],
      "metadata": {
        "id": "LrXYqdkuc2YW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Main Execution"
      ],
      "metadata": {
        "id": "PUg5Gyymc592"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_image_dir = 'NucleiSegmentationDataset/all_images'\n",
        "train_mask_dir = 'NucleiSegmentationDataset/merged_masks'\n",
        "test_image_dir = 'TestDataset/images'\n",
        "test_mask_dir = 'TestDataset/masks'\n",
        "\n",
        "train_dataset = NucleiDataset(train_image_dir, train_mask_dir)\n",
        "test_dataset = NucleiDataset(test_image_dir, test_mask_dir)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "unet_model = UNet()\n",
        "unet_model = train_unet(unet_model, train_loader, num_epochs=20, lr=0.001)\n",
        "\n",
        "predictions, original_test_images, original_test_masks = predict_unet(unet_model, test_loader)\n",
        "precision, recall, f1, accuracy = compute_metrics(np.array(original_test_masks) > 0.5, predictions > 0.5)\n",
        "print(f'Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}, Accuracy: {accuracy:.4f}')\n",
        "visualize_results(original_test_images, original_test_masks, predictions, num_samples=5)"
      ],
      "metadata": {
        "id": "fBQXaE4Gc9sE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}