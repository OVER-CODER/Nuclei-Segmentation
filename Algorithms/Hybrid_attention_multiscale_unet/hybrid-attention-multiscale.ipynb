{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-23T17:02:01.410832Z",
     "iopub.status.busy": "2025-05-23T17:02:01.410594Z",
     "iopub.status.idle": "2025-05-23T17:02:05.716675Z",
     "shell.execute_reply": "2025-05-23T17:02:05.715922Z",
     "shell.execute_reply.started": "2025-05-23T17:02:01.410807Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-image in c:\\users\\aryan pandit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.25.2)\n",
      "Requirement already satisfied: numpy>=1.24 in c:\\users\\aryan pandit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-image) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.11.4 in c:\\users\\aryan pandit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-image) (1.13.1)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\aryan pandit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-image) (3.2.1)\n",
      "Requirement already satisfied: pillow>=10.1 in c:\\users\\aryan pandit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-image) (11.1.0)\n",
      "Requirement already satisfied: imageio!=2.35.0,>=2.33 in c:\\users\\aryan pandit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-image) (2.37.0)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\aryan pandit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-image) (2025.3.30)\n",
      "Requirement already satisfied: packaging>=21 in c:\\users\\aryan pandit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-image) (24.2)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in c:\\users\\aryan pandit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-image) (0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-23T17:47:02.595192Z",
     "iopub.status.busy": "2025-05-23T17:47:02.594482Z",
     "iopub.status.idle": "2025-05-23T17:47:07.296811Z",
     "shell.execute_reply": "2025-05-23T17:47:07.296154Z",
     "shell.execute_reply.started": "2025-05-23T17:47:02.595140Z"
    },
    "id": "td7RbJqHB6Uh",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io, color\n",
    "from skimage.transform import resize\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import f1_score, jaccard_score, precision_score, recall_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.conv1 = nn.Conv2d(in_ch, out_ch, kernel_size=3, stride=stride, padding=1, bias=False).to(device)\n",
    "        self.bn1 = nn.BatchNorm2d(out_ch).to(device)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_ch, out_ch, kernel_size=3, stride=1, padding=1, bias=False).to(device)\n",
    "        self.bn2 = nn.BatchNorm2d(out_ch).to(device)\n",
    "        self.downsample = None\n",
    "        if stride != 1 or in_ch != out_ch:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_ch, out_ch, kernel_size=1, stride=stride, bias=False).to(device),\n",
    "                nn.BatchNorm2d(out_ch).to(device)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class UpSample(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(UpSample, self).__init__()\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.up = nn.ConvTranspose2d(in_ch, out_ch, kernel_size=2, stride=2).to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.up(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tD0-yw4TCk3-"
   },
   "source": [
    "### Hybrid Attention Module (HAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-23T17:47:09.381784Z",
     "iopub.status.busy": "2025-05-23T17:47:09.381377Z",
     "iopub.status.idle": "2025-05-23T17:47:09.392781Z",
     "shell.execute_reply": "2025-05-23T17:47:09.392195Z",
     "shell.execute_reply.started": "2025-05-23T17:47:09.381761Z"
    },
    "id": "YJea7sOmCoSk",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class HybridAttention(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(HybridAttention, self).__init__()\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.channel_attention = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(in_channels, in_channels // 8, kernel_size=1).to(device),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels // 8, in_channels, kernel_size=1).to(device),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.spatial_attention = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels // 8, kernel_size=1).to(device),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels // 8, 1, kernel_size=3, padding=1).to(device),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        channel_attn = self.channel_attention(x)\n",
    "        spatial_attn = self.spatial_attention(x)\n",
    "        channel_refined = x * channel_attn\n",
    "        spatial_refined = x * spatial_attn\n",
    "        # Novel combination: Element-wise multiplication of channel and spatial refined features\n",
    "        attention_out = channel_refined * spatial_refined\n",
    "        return x + attention_out\n",
    "\n",
    "class InceptionModule(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels_1x1, red_channels_3x3, out_channels_3x3, red_channels_5x5, out_channels_5x5, pool_proj):\n",
    "        super(InceptionModule, self).__init__()\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.branch1 = nn.Conv2d(in_channels, out_channels_1x1, kernel_size=1).to(device)\n",
    "        self.branch2_red = nn.Conv2d(in_channels, red_channels_3x3, kernel_size=1).to(device)\n",
    "        self.branch2_conv = nn.Conv2d(red_channels_3x3, out_channels_3x3, kernel_size=3, padding=1).to(device)\n",
    "        self.branch3_red = nn.Conv2d(in_channels, red_channels_5x5, kernel_size=1).to(device)\n",
    "        self.branch3_conv = nn.Conv2d(red_channels_5x5, out_channels_5x5, kernel_size=5, padding=2).to(device)\n",
    "        self.branch4_pool = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
    "        self.branch4_proj = nn.Conv2d(in_channels, pool_proj, kernel_size=1).to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        branch1_out = F.relu(self.branch1(x))\n",
    "        branch2_out = F.relu(self.branch2_conv(F.relu(self.branch2_red(x))))\n",
    "        branch3_out = F.relu(self.branch3_conv(F.relu(self.branch3_red(x))))\n",
    "        branch4_out = F.relu(self.branch4_proj(self.branch4_pool(x)))\n",
    "        outputs = [branch1_out, branch2_out, branch3_out, branch4_out]\n",
    "        return torch.cat(outputs, 1)\n",
    "\n",
    "class HMSAModule(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels_1x1, red_channels_3x3, out_channels_3x3, red_channels_5x5, out_channels_5x5, pool_proj):\n",
    "        super(HMSAModule, self).__init__()\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.inception = InceptionModule(in_channels, out_channels_1x1, red_channels_3x3, out_channels_3x3, red_channels_5x5, out_channels_5x5, pool_proj).to(device)\n",
    "        inception_output_channels = out_channels_1x1 + out_channels_3x3 + out_channels_5x5 + pool_proj\n",
    "        self.attention = HybridAttention(inception_output_channels).to(device)\n",
    "        if inception_output_channels != in_channels:\n",
    "            self.projection = nn.Conv2d(inception_output_channels, in_channels, kernel_size=1).to(device)\n",
    "        else:\n",
    "            self.projection = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        inception_out = self.inception(x)\n",
    "        attention_out = self.attention(inception_out)\n",
    "        if self.projection is not None:\n",
    "            attention_out = self.projection(attention_out)\n",
    "        hmsam_output = x + attention_out\n",
    "        return hmsam_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "40DGtAzoCvE2"
   },
   "source": [
    "### HMSAM-UNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-23T17:47:09.788599Z",
     "iopub.status.busy": "2025-05-23T17:47:09.788324Z",
     "iopub.status.idle": "2025-05-23T17:47:09.798132Z",
     "shell.execute_reply": "2025-05-23T17:47:09.797455Z",
     "shell.execute_reply.started": "2025-05-23T17:47:09.788579Z"
    },
    "id": "hgUzlAcHCyOb",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class HMSAM_ResUNet(nn.Module):\n",
    "    def __init__(self, num_channels=1, out_channels=1):\n",
    "        super(HMSAM_ResUNet, self).__init__()\n",
    "\n",
    "        self.enc1_res1 = ResidualBlock(num_channels, 64)\n",
    "        self.enc1_res2 = ResidualBlock(64, 64)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.enc2_res1 = ResidualBlock(64, 128)\n",
    "        self.enc2_res2 = ResidualBlock(128, 128)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.enc3_res1 = ResidualBlock(128, 256)\n",
    "        self.enc3_res2 = ResidualBlock(256, 256)\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.enc4_res1 = ResidualBlock(256, 512)\n",
    "        self.enc4_res2 = ResidualBlock(512, 512)\n",
    "        self.pool4 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.hmsam = HMSAModule(in_channels=512,\n",
    "                                    out_channels_1x1=128,\n",
    "                                    red_channels_3x3=96, out_channels_3x3=192,\n",
    "                                    red_channels_5x5=32, out_channels_5x5=64,\n",
    "                                    pool_proj=128)\n",
    "\n",
    "        self.up4 = UpSample(512, 512)\n",
    "        self.dec4_res1 = ResidualBlock(512 + 512, 512)\n",
    "        self.dec4_res2 = ResidualBlock(512, 512)\n",
    "\n",
    "        self.up3 = UpSample(512, 256)\n",
    "        self.dec3_res1 = ResidualBlock(256 + 256, 256)\n",
    "        self.dec3_res2 = ResidualBlock(256, 256)\n",
    "\n",
    "        self.up2 = UpSample(256, 128)\n",
    "        self.dec2_res1 = ResidualBlock(128 + 128, 128)\n",
    "        self.dec2_res2 = ResidualBlock(128, 128)\n",
    "\n",
    "        self.up1 = UpSample(128, 64)\n",
    "        self.dec1_res1 = ResidualBlock(64 + 64, 64)\n",
    "        self.dec1_res2 = ResidualBlock(64, 64)\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.final = nn.Conv2d(64, out_channels, kernel_size=1).to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        e1 = self.enc1_res2(self.enc1_res1(x))\n",
    "        p1 = self.pool1(e1)\n",
    "\n",
    "        e2 = self.enc2_res2(self.enc2_res1(p1))\n",
    "        p2 = self.pool2(e2)\n",
    "\n",
    "        e3 = self.enc3_res2(self.enc3_res1(p2))\n",
    "        p3 = self.pool3(e3)\n",
    "\n",
    "        e4 = self.enc4_res2(self.enc4_res1(p3))\n",
    "        bridge = self.pool4(e4)\n",
    "\n",
    "        hmsam_out = self.hmsam(bridge)\n",
    "\n",
    "        # Decoder\n",
    "        up4 = self.up4(hmsam_out)\n",
    "        d4 = self.dec4_res2(self.dec4_res1(torch.cat([up4, e4], dim=1)))\n",
    "\n",
    "        up3 = self.up3(d4)\n",
    "        d3 = self.dec3_res2(self.dec3_res1(torch.cat([up3, e3], dim=1)))\n",
    "\n",
    "        up2 = self.up2(d3)\n",
    "        d2 = self.dec2_res2(self.dec2_res1(torch.cat([up2, e2], dim=1)))\n",
    "\n",
    "        up1 = self.up1(d2)\n",
    "        d1 = self.dec1_res2(self.dec1_res1(torch.cat([up1, e1], dim=1)))\n",
    "\n",
    "        return torch.sigmoid(self.final(d1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Njue4XF8C4-w"
   },
   "source": [
    "### Data Loading and Processing (Adapt for your dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-23T17:47:10.133287Z",
     "iopub.status.busy": "2025-05-23T17:47:10.132736Z",
     "iopub.status.idle": "2025-05-23T17:47:10.141042Z",
     "shell.execute_reply": "2025-05-23T17:47:10.140325Z",
     "shell.execute_reply.started": "2025-05-23T17:47:10.133264Z"
    },
    "id": "6SGvxjx5C8VK",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class NucleiDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, image_size=(128, 128)):\n",
    "        self.image_size = image_size\n",
    "        self.image_paths = []\n",
    "        self.mask_paths = []\n",
    "        image_files = sorted(os.listdir(image_dir))\n",
    "        mask_files = sorted(os.listdir(mask_dir))\n",
    "\n",
    "        for img_file, mask_file in zip(image_files, mask_files):\n",
    "            img_path = os.path.join(image_dir, img_file)\n",
    "            mask_path = os.path.join(mask_dir, mask_file)\n",
    "            self.image_paths.append(img_path)\n",
    "            self.mask_paths.append(mask_path)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        mask_path = self.mask_paths[idx]\n",
    "\n",
    "        img = io.imread(img_path)\n",
    "        mask = io.imread(mask_path)\n",
    "\n",
    "        if img.ndim == 3 and img.shape[2] == 4:\n",
    "            img = img[:, :, :3]\n",
    "\n",
    "        if mask.ndim == 3:\n",
    "            if mask.shape[2] == 4:\n",
    "                mask = mask[:, :, :3]\n",
    "            mask = color.rgb2gray(mask)\n",
    "        elif mask.ndim == 2:\n",
    "            pass\n",
    "\n",
    "        img_resized = resize(img, self.image_size, anti_aliasing=True)\n",
    "        if img_resized.ndim == 3:\n",
    "            img_gray = color.rgb2gray(img_resized)\n",
    "        else:\n",
    "            img_gray = img_resized\n",
    "\n",
    "        mask_resized = resize(mask, self.image_size, anti_aliasing=True)\n",
    "        mask_binary = mask_resized > 0.5\n",
    "\n",
    "        # CRUCIAL CHANGE: Resize the original images and masks too!\n",
    "        img_resized_orig = resize(img, self.image_size, anti_aliasing=True)\n",
    "        mask_resized_orig = resize(mask, self.image_size, anti_aliasing=True)\n",
    "\n",
    "\n",
    "        return torch.tensor(np.expand_dims(img_gray.astype(np.float32), axis=0)), \\\n",
    "               torch.tensor(np.expand_dims(mask_binary.astype(np.float32), axis=0)), \\\n",
    "               img_resized_orig, mask_resized_orig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ykBzC_QODCaO"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-23T17:47:10.721306Z",
     "iopub.status.busy": "2025-05-23T17:47:10.720807Z",
     "iopub.status.idle": "2025-05-23T17:47:10.726565Z",
     "shell.execute_reply": "2025-05-23T17:47:10.725905Z",
     "shell.execute_reply.started": "2025-05-23T17:47:10.721279Z"
    },
    "id": "rfRNiyCMDEQC",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, num_epochs=10, lr=1e-3):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for img_tensor, mask_tensor, _, _ in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "            img_tensor, mask_tensor = img_tensor.to(device), mask_tensor.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(img_tensor)\n",
    "            loss = criterion(output, mask_tensor)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss / len(train_loader):.4f}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zS3FKOE8DHqf"
   },
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-23T17:47:11.239791Z",
     "iopub.status.busy": "2025-05-23T17:47:11.239114Z",
     "iopub.status.idle": "2025-05-23T17:47:11.244621Z",
     "shell.execute_reply": "2025-05-23T17:47:11.243771Z",
     "shell.execute_reply.started": "2025-05-23T17:47:11.239765Z"
    },
    "id": "7qyIvVRDDLnn",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def predict_model(model, test_loader):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    original_images = []\n",
    "    ground_truth_masks = []\n",
    "    with torch.no_grad():\n",
    "        for img_tensor, mask_tensor, original_img, original_mask in tqdm(test_loader, desc=\"Predicting\"):\n",
    "            img_tensor = img_tensor.to(device)\n",
    "            output = model(img_tensor).cpu().numpy()\n",
    "            preds.extend(output)\n",
    "            original_images.extend(original_img)\n",
    "            ground_truth_masks.extend(original_mask)\n",
    "    return np.array(preds), original_images, ground_truth_masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zm1tngWWDO2I"
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-23T17:47:11.982005Z",
     "iopub.status.busy": "2025-05-23T17:47:11.981756Z",
     "iopub.status.idle": "2025-05-23T17:47:11.987104Z",
     "shell.execute_reply": "2025-05-23T17:47:11.986461Z",
     "shell.execute_reply.started": "2025-05-23T17:47:11.981987Z"
    },
    "id": "SyMlz92PDR1x",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_metrics(y_true, y_pred, threshold=0.5):\n",
    "    y_pred_binary = y_pred > threshold\n",
    "    y_true_flat = y_true.flatten()\n",
    "    y_pred_flat = y_pred_binary.flatten()\n",
    "\n",
    "    TP = np.sum((y_true_flat == 1) & (y_pred_flat == 1))\n",
    "    TN = np.sum((y_true_flat == 0) & (y_pred_flat == 0))\n",
    "    FP = np.sum((y_true_flat == 0) & (y_pred_flat == 1))\n",
    "    FN = np.sum((y_true_flat == 1) & (y_pred_flat == 0))\n",
    "\n",
    "    precision = TP / (TP + FP + 1e-8)\n",
    "    recall = TP / (TP + FN + 1e-8)\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN + 1e-8)\n",
    "    f1_score = 2 * precision * recall / (precision + recall + 1e-8)\n",
    "\n",
    "    return precision, recall, f1_score, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Apwy7BoJDUlh"
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-23T17:47:12.769212Z",
     "iopub.status.busy": "2025-05-23T17:47:12.768641Z",
     "iopub.status.idle": "2025-05-23T17:47:12.775307Z",
     "shell.execute_reply": "2025-05-23T17:47:12.774459Z",
     "shell.execute_reply.started": "2025-05-23T17:47:12.769179Z"
    },
    "id": "Zd9YOX6zDXse",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def visualize_results(original_images, ground_truth_masks, predictions, num_samples=5, save_dir='results/hmsam_unet'):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    for i in range(min(num_samples, len(original_images))):\n",
    "        plt.figure(figsize=(15, 5))\n",
    "\n",
    "        # Original image\n",
    "        plt.subplot(1, 3, 1)\n",
    "        if original_images[i].ndim == 3:\n",
    "            plt.imshow(original_images[i])\n",
    "        else:\n",
    "            plt.imshow(original_images[i], cmap='gray')\n",
    "        plt.title('Original Image')\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Ground truth mask\n",
    "        plt.subplot(1, 3, 2)\n",
    "        if ground_truth_masks[i].ndim == 3:\n",
    "            plt.imshow(ground_truth_masks[i])\n",
    "        else:\n",
    "            plt.imshow(ground_truth_masks[i], cmap='gray')\n",
    "        plt.title('Ground Truth Mask')\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Prediction (binarized output)\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(predictions[i][0] > 0.5, cmap='gray')\n",
    "        plt.title('Prediction')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.savefig(os.path.join(save_dir, f'prediction_result_{i}.png'))\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KKtv8InsDbhh"
   },
   "source": [
    "### Main Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-23T17:55:06.897588Z",
     "iopub.status.busy": "2025-05-23T17:55:06.897316Z",
     "iopub.status.idle": "2025-05-23T18:23:55.898952Z",
     "shell.execute_reply": "2025-05-23T18:23:55.898238Z",
     "shell.execute_reply.started": "2025-05-23T17:55:06.897567Z"
    },
    "id": "LMFV9LyXDfiD",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100%|██████████| 14/14 [00:33<00:00,  2.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Loss: 0.4252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 55/55 [00:12<00:00,  4.29it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     25\u001b[39m binary_original_test_masks = [resize(mask, (\u001b[32m128\u001b[39m, \u001b[32m128\u001b[39m), anti_aliasing=\u001b[38;5;28;01mTrue\u001b[39;00m) > \u001b[32m0.5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m mask \u001b[38;5;129;01min\u001b[39;00m original_test_masks]\n\u001b[32m     26\u001b[39m binary_original_test_masks_np = np.array([np.expand_dims(mask.astype(np.float32), axis=\u001b[32m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m mask \u001b[38;5;129;01min\u001b[39;00m binary_original_test_masks])\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m precision, recall, f1, accuracy = \u001b[43mevaluate_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbinary_original_test_masks_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mPrecision: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprecision\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Recall: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrecall\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, F1-Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf1\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m     31\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSaving visualization results...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mevaluate_predictions\u001b[39m\u001b[34m(predictions, gt_masks)\u001b[39m\n\u001b[32m      5\u001b[39m recalls = []\n\u001b[32m      6\u001b[39m accuracies = []\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m pred_mask, fname \u001b[38;5;129;01min\u001b[39;00m predictions:\n\u001b[32m      9\u001b[39m     gt_mask = gt_masks.get(fname)\n\u001b[32m     10\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gt_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mValueError\u001b[39m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    train_image_dir = 'Dataset/NucleiSegmentationDataset/all_images' \n",
    "    train_mask_dir = 'Dataset/NucleiSegmentationDataset/merged_masks'\n",
    "    test_image_dir = 'Dataset/TestDataset/images'\n",
    "    test_mask_dir = 'Dataset/TestDataset/masks'\n",
    "    \n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    train_dataset = NucleiDataset(train_image_dir, train_mask_dir)\n",
    "    test_dataset = NucleiDataset(test_image_dir, test_mask_dir)\n",
    "\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "    hmsam_unet_model = HMSAM_ResUNet(num_channels=1, out_channels=1) # Assuming grayscale input\n",
    "\n",
    "    hmsam_unet_model = train_model(hmsam_unet_model, train_loader, num_epochs=5, lr=0.001)\n",
    "\n",
    "    predictions, original_test_images, original_test_masks = predict_model(hmsam_unet_model, test_loader)\n",
    "\n",
    "    binary_original_test_masks = [resize(mask, (128, 128), anti_aliasing=True) > 0.5 for mask in original_test_masks]\n",
    "    binary_original_test_masks_np = np.array([np.expand_dims(mask.astype(np.float32), axis=0) for mask in binary_original_test_masks])\n",
    "\n",
    "    precision, recall, f1, accuracy = compute_metrics(binary_original_test_masks_np, predictions, threshold=0.5)\n",
    "    print(f'Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}, Accuracy: {accuracy:.4f}')\n",
    "\n",
    "    print(\"Saving visualization results...\")\n",
    "    visualize_results(original_test_images, original_test_masks, predictions, num_samples=5)\n",
    "    print(\"Visualization complete. Check 'results/hmsam_unet' directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1454704,
     "sourceId": 2407101,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7492953,
     "sourceId": 11918784,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
